### Назначение платформы

AI Learning — это облачная среда, где пользователь учится через диалог с **LLM-ментором** — большим языковым моделем-агентом. Платформа объединяет три вида активности — **теория**, **практика** и **симуляции** — в одном чате, превращая беседу в полноценный учебный процесс.


---

### Ключевые возможности

#### Персонализированные треки

* Адаптивная учебная программа формируется LLM-ментором на основе целей, уровня знаний и темпа пользователя.
* Треки динамически перестраиваются: агент предлагает новые модули, пропускает знакомый материал или углубляет темы при необходимости.

#### Единый чат-интерфейс

* **Теория**: краткие объяснения, примеры и ссылки на конспект без переключения вкладок.
* **Практика**: задачи с автоматической проверкой кода или ответов прямо в диалоге.
* **Симуляции**: ролевая игра с LLM-аватарами, где пользователь принимает решения и получает мгновочную обратную связь.
* Встроенные кнопки («/hint», «/summarize», «/next») ускоряют навигацию по материалу.

#### Интерактивный конспект

* Создаётся при старте трека и автоматически пополняется ключевыми выводами из чата.


#### Ментор-ассистент

* Отвечает на вопросы о платформе, создает новые треки, корректирует стиль обучения (больше практики, меньше теории и т. д.).
* Поддерживает промежуточные итоги и рефлексию: «Чему вы научились за сессию?»

---

### Структура интерфейса

**Landing**
Короткий обзор преимуществ: персонализированные треки, AI-ментор, практика в чате, аналитика прогресса.

**Мои треки**
Карточки текущих программ с индикаторами прогресса и единым чатом-ассистентом для управления обучением.

**Учебный трек**
Главное рабочее пространство



----

PM для LLM специалиста 

Я LLM разработчик и хочу узнать сторону бизнеса в LLM приложениямх 

Понимать бизнес метрики и развитие LLM продуктов с точки зрения бизнеса

---

### Быстрый старт (локально)

1) Установить зависимости
```bash
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

2) Бэкенд
```bash
make api  # или python -m uvicorn backend.app.main:app --reload --port 8000
```

3) Фронтенд
```bash
cd frontend && pnpm i && pnpm dev
```

Создайте `frontend/.env.local` с базовым URL:
```
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_FIXED_DEVICE_ID=dev-device
```

---

### Вызов разговорных агентов

Бэкенд предоставляет JSON‑маршруты для трёх диалоговых агентов. Ответ — простой текст в поле `message`.

- Наставник чата:
```bash
curl -sX POST http://localhost:8000/agents/mentor_chat/v1/reply \
  -H 'Content-Type: application/json' \
  -d '{"session_id":"dev-s1","memory":"inmem","user_message":"Как начать?"}'
```

- Тренер практики:
```bash
curl -sX POST http://localhost:8000/agents/practice_coach/v1/hint \
  -H 'Content-Type: application/json' \
  -d '{"session_id":"dev-s1","memory":"inmem","user_message":"Дай первый шаг"}'
```

- Ведущий симуляции:
```bash
curl -sX POST http://localhost:8000/agents/simulation_mentor/v1/turn \
  -H 'Content-Type: application/json' \
  -d '{"session_id":"dev-s1","memory":"inmem","user_message":"Смоделируй разговор"}'
```

При `apply_side_effects=true` ответы будут сохранены в соответствующую ветку чата в БД.

---

### Фронтенд‑клиент

В `frontend/src/lib/api.ts` добавлены методы:
- `runMentorChat({ sessionId?, message, memory?, applySideEffects? })`
- `runPracticeCoach({ sessionId?, message, memory?, applySideEffects? })`
- `runSimulationMentor({ sessionId?, message, memory?, applySideEffects? })`

Использование (пример):
```ts
import { api } from '@/lib/api'

const res = await api.runMentorChat({ sessionId, message: 'Привет!' })
console.log(res.message)
```
